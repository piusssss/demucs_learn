#!/usr/bin/env python3
"""
å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„é¢‘è°±è¾“å‡º
è‡ªåŠ¨æ£€æŸ¥separatedæ–‡ä»¶å¤¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿è¡Œdemucsç”Ÿæˆ
"""

import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import soundfile as sf
from pathlib import Path
import subprocess
import sys
import shutil
import json
from datetime import datetime
import pandas as pd

# ==================== é…ç½®åŒºåŸŸ ==================== 
# åœ¨è¿™é‡Œç¡¬ç¼–ç ä½ çš„é…ç½®

# æ¨¡å‹é…ç½®
MODEL_NAME = "htt100"  # è¦å¯¹æ¯”çš„æ¨¡å‹åç§°

# MUSDBæ­Œæ›²ç›®å½•ï¼ˆåŒ…å«mixture.wavå’Œå„æºçš„.wavæ–‡ä»¶ï¼‰
MUSDB_TRACK_DIR = r"data\musdb18_hq_test\test\Carlos Gonzalez - A Place For Us"

# æºåç§°ï¼ˆè¦åˆ†æçš„æºï¼‰
SOURCES = ["drums", "bass", "other", "vocals"]  # åˆ†ææ‰€æœ‰4ä¸ªæº

# è¾“å‡ºç›®å½•ï¼ˆä¼šåœ¨æ­¤ç›®å½•ä¸‹åˆ›å»ºæ¨¡å‹åå­æ–‡ä»¶å¤¹ï¼‰
OUTPUT_DIR = "spectrum_analysis_real"

# Demucså‚æ•°
SHIFTS = 1
OVERLAP = 0.25

# ==================== é…ç½®åŒºåŸŸç»“æŸ ====================


def check_and_generate_separation(model_name, musdb_track_dir):
    """
    æ£€æŸ¥separatedæ–‡ä»¶å¤¹æ˜¯å¦æœ‰å¯¹åº”éŸ³é¢‘ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿è¡Œdemucsç”Ÿæˆ
    
    å‚æ•°:
        model_name: æ¨¡å‹åç§°
        musdb_track_dir: MUSDBæ­Œæ›²ç›®å½•ï¼ˆåŒ…å«mixture.wavï¼‰
    
    è¿”å›:
        separated_dir: åˆ†ç¦»ç»“æœç›®å½•
    """
    track_path = Path(musdb_track_dir)
    track_name = track_path.name  # æ­Œæ›²åç§°ï¼ˆç›®å½•åï¼‰
    mixture_file = track_path / "mixture.wav"
    
    # æ£€æŸ¥mixture.wavæ˜¯å¦å­˜åœ¨
    if not mixture_file.exists():
        print(f"âœ— é”™è¯¯: æ‰¾ä¸åˆ° {mixture_file}")
        sys.exit(1)
    
    # separatedæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä½¿ç”¨æ­Œæ›²åä½œä¸ºæ–‡ä»¶å¤¹åï¼‰
    separated_dir = Path("separated") / model_name / track_name
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if separated_dir.exists():
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰€æœ‰æºçš„æ–‡ä»¶
        sources = ["drums", "bass", "other", "vocals"]
        all_exist = all((separated_dir / f"{source}.wav").exists() for source in sources)
        
        if all_exist:
            print(f"âœ“ æ‰¾åˆ°å·²å­˜åœ¨çš„åˆ†ç¦»ç»“æœ: {separated_dir}")
            return separated_dir
        else:
            print(f"âš  åˆ†ç¦»ç»“æœä¸å®Œæ•´ï¼Œé‡æ–°ç”Ÿæˆ...")
    
    # éœ€è¦ç”Ÿæˆ
    print(f"âš™ è¿è¡Œdemucsç”Ÿæˆåˆ†ç¦»ç»“æœ...")
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  éŸ³é¢‘: {mixture_file}")
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        "demucs",
        "--repo", "./release_models",
        "-n", model_name,
        f"--shifts={SHIFTS}",
        "--overlap", str(OVERLAP),
        str(mixture_file)
    ]
    
    print(f"  å‘½ä»¤: {' '.join(cmd)}")
    
    # è¿è¡Œå‘½ä»¤
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print(f"âœ“ åˆ†ç¦»å®Œæˆ")
        
        # demucsä¼šè¾“å‡ºåˆ° separated/model_name/mixture/
        # éœ€è¦é‡å‘½åä¸º separated/model_name/track_name/
        default_output = Path("separated") / model_name / "mixture"
        
        if default_output.exists() and not separated_dir.exists():
            print(f"  é‡å‘½åè¾“å‡ºç›®å½•: mixture -> {track_name}")
            import shutil
            shutil.move(str(default_output), str(separated_dir))
        
        return separated_dir
    except subprocess.CalledProcessError as e:
        print(f"âœ— åˆ†ç¦»å¤±è´¥:")
        print(e.stderr)
        sys.exit(1)


def load_source_audio(source_dir, source_name, is_real=False):
    """
    åŠ è½½æŒ‡å®šæºçš„éŸ³é¢‘
    
    å‚æ•°:
        source_dir: æºæ–‡ä»¶ç›®å½•
        source_name: æºåç§°
        is_real: æ˜¯å¦æ˜¯çœŸå®æºï¼ˆMUSDBæ ¼å¼ï¼‰
    
    è¿”å›:
        audio: éŸ³é¢‘æ•°æ®
        sr: é‡‡æ ·ç‡
    """
    if is_real:
        # MUSDBçœŸå®æºæ–‡ä»¶åæ ¼å¼
        audio_file = source_dir / f"{source_name}.wav"
    else:
        # æ¨¡å‹è¾“å‡ºæ–‡ä»¶åæ ¼å¼
        audio_file = source_dir / f"{source_name}.wav"
    
    if not audio_file.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_file}")
    
    print(f"  åŠ è½½: {audio_file}")
    audio, sr = librosa.load(str(audio_file), sr=None, mono=True)
    
    return audio, sr


def plot_spectrum_comparison(audio_real, audio_model, sr, source_name, save_path):
    """
    å¯¹æ¯”çœŸå®æºå’Œæ¨¡å‹è¾“å‡ºçš„é¢‘è°±
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    # è®¡ç®—STFT
    n_fft = 2048
    hop_length = 512
    
    spec_real = librosa.stft(audio_real, n_fft=n_fft, hop_length=hop_length)
    spec_model = librosa.stft(audio_model, n_fft=n_fft, hop_length=hop_length)
    
    # è½¬æ¢ä¸ºdB
    spec_real_db = librosa.amplitude_to_db(np.abs(spec_real), ref=np.max)
    spec_model_db = librosa.amplitude_to_db(np.abs(spec_model), ref=np.max)
    
    # è®¡ç®—å·®å¼‚
    diff = spec_model_db - spec_real_db
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle(f'{source_name.capitalize()} - Real vs Model Comparison', 
                 fontsize=16, fontweight='bold')
    
    # 1. çœŸå®æºé¢‘è°±
    img1 = librosa.display.specshow(spec_real_db, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 0],
                                     cmap='viridis', vmin=-80, vmax=0)
    axes[0, 0].set_title('Real (Ground Truth)', fontsize=12, fontweight='bold')
    axes[0, 0].set_ylabel('Frequency (Hz)')
    axes[0, 0].set_ylim([0, 4000])
    fig.colorbar(img1, ax=axes[0, 0], format='%+2.0f dB')
    
    # 2. æ¨¡å‹è¾“å‡ºé¢‘è°±
    img2 = librosa.display.specshow(spec_model_db, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 1],
                                     cmap='viridis', vmin=-80, vmax=0)
    axes[0, 1].set_title(f'{MODEL_NAME} (Predicted)', fontsize=12, fontweight='bold')
    axes[0, 1].set_ylabel('Frequency (Hz)')
    axes[0, 1].set_ylim([0, 4000])
    fig.colorbar(img2, ax=axes[0, 1], format='%+2.0f dB')
    
    # 3. å·®å¼‚å›¾
    img3 = librosa.display.specshow(diff, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[1, 0],
                                     cmap='RdBu_r', vmin=-20, vmax=20)
    axes[1, 0].set_title('Difference (Model - Real)', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('Time (s)')
    axes[1, 0].set_ylabel('Frequency (Hz)')
    axes[1, 0].set_ylim([0, 4000])
    fig.colorbar(img3, ax=axes[1, 0], format='%+2.0f dB')
    
    # 4. é¢‘ç‡å‰–é¢å¯¹æ¯”
    mag_real = np.abs(spec_real).mean(axis=1)
    mag_model = np.abs(spec_model).mean(axis=1)
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    
    axes[1, 1].plot(freqs, 20*np.log10(mag_real + 1e-10), 
                   label='Real', linewidth=2, alpha=0.8)
    axes[1, 1].plot(freqs, 20*np.log10(mag_model + 1e-10), 
                   label=MODEL_NAME, linewidth=2, alpha=0.8)
    axes[1, 1].set_xlim([0, 2000])
    axes[1, 1].set_xlabel('Frequency (Hz)')
    axes[1, 1].set_ylabel('Magnitude (dB)')
    axes[1, 1].set_title('Average Frequency Profile', fontsize=12, fontweight='bold')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # æ ‡æ³¨ç‰¹å®šé¢‘æ®µï¼ˆæ ¹æ®æºç±»å‹ï¼‰
    if source_name.lower() == 'bass':
        for ax in [axes[0, 0], axes[0, 1], axes[1, 0]]:
            ax.axhspan(40, 250, alpha=0.1, color='red')
        axes[1, 1].axvspan(40, 250, alpha=0.2, color='red', label='Bass Range')
    elif source_name.lower() == 'drums':
        for ax in [axes[0, 0], axes[0, 1], axes[1, 0]]:
            ax.axhspan(50, 500, alpha=0.1, color='orange')
        axes[1, 1].axvspan(50, 500, alpha=0.2, color='orange', label='Drums Range')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ é¢‘è°±å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def analyze_spectral_similarity(audio_real, audio_model, sr, source_name):
    """
    åˆ†æé¢‘è°±ç›¸ä¼¼åº¦
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        similarity_stats: ç›¸ä¼¼åº¦ç»Ÿè®¡å­—å…¸
    """
    n_fft = 2048
    spec_real = librosa.stft(audio_real, n_fft=n_fft)
    spec_model = librosa.stft(audio_model, n_fft=n_fft)
    
    # 1. æ•´ä½“é¢‘è°±ç›¸å…³ç³»æ•°
    mag_real = np.abs(spec_real).flatten()
    mag_model = np.abs(spec_model).flatten()
    correlation = np.corrcoef(mag_real, mag_model)[0, 1]
    
    # 2. ä½™å¼¦ç›¸ä¼¼åº¦
    cosine_sim = np.dot(mag_real, mag_model) / (np.linalg.norm(mag_real) * np.linalg.norm(mag_model) + 1e-10)
    
    # 3. å„é¢‘æ®µçš„ç›¸å…³ç³»æ•°
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    bands = {
        'Sub-bass (20-60 Hz)': (20, 60),
        'Bass (60-250 Hz)': (60, 250),
        'Low-mid (250-500 Hz)': (250, 500),
        'Mid (500-2000 Hz)': (500, 2000),
        'High (2000-8000 Hz)': (2000, 8000),
    }
    
    band_correlations = {}
    for band_name, (f_low, f_high) in bands.items():
        bins = np.where((freqs >= f_low) & (freqs <= f_high))[0]
        if len(bins) > 0:
            real_band = np.abs(spec_real[bins, :]).flatten()
            model_band = np.abs(spec_model[bins, :]).flatten()
            if len(real_band) > 1:
                band_corr = np.corrcoef(real_band, model_band)[0, 1]
                band_correlations[band_name] = float(band_corr)
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Spectral Similarity Analysis")
    print(f"{'='*70}")
    print(f"Overall Correlation: {correlation:.4f} (1.0 = perfect match)")
    print(f"Cosine Similarity: {cosine_sim:.4f} (1.0 = perfect match)")
    print(f"\nBand-wise Correlations:")
    for band_name, corr in band_correlations.items():
        print(f"  {band_name:<25} {corr:.4f}")
    print(f"{'='*70}\n")
    
    return {
        'overall_correlation': float(correlation),
        'cosine_similarity': float(cosine_sim),
        'band_correlations': band_correlations
    }


def analyze_error_energy(audio_real, audio_model, sr, source_name):
    """
    åˆ†æè¯¯å·®èƒ½é‡ï¼ˆç±»ä¼¼SDRçš„è®¡ç®—ï¼‰
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        error_stats: è¯¯å·®ç»Ÿè®¡å­—å…¸
    """
    n_fft = 2048
    spec_real = librosa.stft(audio_real, n_fft=n_fft)
    spec_model = librosa.stft(audio_model, n_fft=n_fft)
    
    # è¯¯å·®é¢‘è°±
    error_spec = spec_model - spec_real
    
    # å„é¢‘æ®µçš„è¯¯å·®èƒ½é‡
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    bands = {
        'Sub-bass (20-60 Hz)': (20, 60),
        'Bass (60-250 Hz)': (60, 250),
        'Low-mid (250-500 Hz)': (250, 500),
        'Mid (500-2000 Hz)': (500, 2000),
        'High (2000-8000 Hz)': (2000, 8000),
    }
    
    error_stats = {}
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Error Energy Analysis")
    print(f"{'='*70}")
    print(f"{'Frequency Band':<25} {'Pseudo-SDR':<15} {'Error Ratio':<15}")
    print(f"{'-'*70}")
    
    for band_name, (f_low, f_high) in bands.items():
        bins = np.where((freqs >= f_low) & (freqs <= f_high))[0]
        if len(bins) > 0:
            real_energy = np.sum(np.abs(spec_real[bins, :]) ** 2)
            error_energy = np.sum(np.abs(error_spec[bins, :]) ** 2)
            
            # ç±»ä¼¼SDRçš„è®¡ç®—
            pseudo_sdr = 10 * np.log10(real_energy / (error_energy + 1e-10))
            error_ratio = error_energy / (real_energy + 1e-10)
            
            print(f"{band_name:<25} {pseudo_sdr:<15.3f} {error_ratio:<15.4f}")
            
            error_stats[band_name] = {
                'error_energy': float(error_energy),
                'pseudo_sdr': float(pseudo_sdr),
                'error_ratio': float(error_ratio)
            }
    
    # æ€»ä½“è¯¯å·®
    total_real_energy = np.sum(np.abs(spec_real) ** 2)
    total_error_energy = np.sum(np.abs(error_spec) ** 2)
    total_pseudo_sdr = 10 * np.log10(total_real_energy / (total_error_energy + 1e-10))
    total_error_ratio = total_error_energy / (total_real_energy + 1e-10)
    
    print(f"{'-'*70}")
    print(f"{'Total':<25} {total_pseudo_sdr:<15.3f} {total_error_ratio:<15.4f}")
    print(f"{'='*70}\n")
    
    error_stats['Total'] = {
        'error_energy': float(total_error_energy),
        'pseudo_sdr': float(total_pseudo_sdr),
        'error_ratio': float(total_error_ratio)
    }
    
    return error_stats


def analyze_silence_leakage(audio_real, audio_model, sr, source_name):
    """
    åˆ†æé™éŸ³æ®µæ³„æ¼
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        leakage_stats: æ³„æ¼ç»Ÿè®¡å­—å…¸
    """
    # è®¡ç®—èƒ½é‡åŒ…ç»œ
    frame_length = 2048
    hop_length = 512
    
    real_rms = librosa.feature.rms(y=audio_real, frame_length=frame_length, hop_length=hop_length)[0]
    model_rms = librosa.feature.rms(y=audio_model, frame_length=frame_length, hop_length=hop_length)[0]
    
    # å®šä¹‰é™éŸ³é˜ˆå€¼ï¼ˆçœŸå®æºRMSæœ€ä½10%çš„å¸§ï¼‰
    silence_threshold = np.percentile(real_rms, 10)
    
    # æ‰¾åˆ°é™éŸ³å¸§å’Œæ´»è·ƒå¸§
    silence_frames = real_rms < silence_threshold
    active_frames = ~silence_frames
    
    # è®¡ç®—é™éŸ³æ®µå’Œæ´»è·ƒæ®µçš„è¾“å‡º
    silence_leakage = np.mean(model_rms[silence_frames]) if np.any(silence_frames) else 0
    active_output = np.mean(model_rms[active_frames]) if np.any(active_frames) else 0
    
    leakage_ratio = silence_leakage / active_output if active_output > 0 else 0
    
    # è®¡ç®—é™éŸ³æ®µçš„èƒ½é‡å æ¯”
    silence_energy = np.sum(model_rms[silence_frames] ** 2) if np.any(silence_frames) else 0
    total_energy = np.sum(model_rms ** 2)
    silence_energy_ratio = silence_energy / total_energy if total_energy > 0 else 0
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Silence Leakage Analysis")
    print(f"{'='*70}")
    print(f"Silence threshold (RMS): {silence_threshold:.6f}")
    print(f"Silence frames: {np.sum(silence_frames)} / {len(silence_frames)} ({100*np.sum(silence_frames)/len(silence_frames):.1f}%)")
    print(f"Model output in silence: {silence_leakage:.6f} RMS")
    print(f"Model output in active: {active_output:.6f} RMS")
    print(f"Leakage ratio: {leakage_ratio:.4f} (lower is better)")
    print(f"Silence energy ratio: {100*silence_energy_ratio:.2f}% of total output")
    print(f"{'='*70}\n")
    
    return {
        'silence_threshold': float(silence_threshold),
        'silence_frames_count': int(np.sum(silence_frames)),
        'total_frames': int(len(silence_frames)),
        'silence_frames_percentage': float(100 * np.sum(silence_frames) / len(silence_frames)),
        'silence_leakage_rms': float(silence_leakage),
        'active_output_rms': float(active_output),
        'leakage_ratio': float(leakage_ratio),
        'silence_energy_ratio': float(silence_energy_ratio)
    }


def analyze_temporal_alignment(audio_real, audio_model, sr, source_name):
    """
    åˆ†ææ—¶é—´å¯¹é½å’Œç¬æ€å‡†ç¡®åº¦
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        temporal_stats: æ—¶é—´å¯¹é½ç»Ÿè®¡å­—å…¸
    """
    # è®¡ç®—onsetï¼ˆç¬æ€èµ·å§‹ç‚¹ï¼‰
    onset_real = librosa.onset.onset_detect(y=audio_real, sr=sr, units='time')
    onset_model = librosa.onset.onset_detect(y=audio_model, sr=sr, units='time')
    
    # è®¡ç®—onsetåŒ¹é…åº¦
    tolerance = 0.05  # 50mså®¹å·®
    matched_onsets = 0
    
    for t_real in onset_real:
        if np.any(np.abs(onset_model - t_real) < tolerance):
            matched_onsets += 1
    
    onset_precision = matched_onsets / len(onset_model) if len(onset_model) > 0 else 0
    onset_recall = matched_onsets / len(onset_real) if len(onset_real) > 0 else 0
    onset_f1 = 2 * onset_precision * onset_recall / (onset_precision + onset_recall) if (onset_precision + onset_recall) > 0 else 0
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Temporal Alignment Analysis")
    print(f"{'='*70}")
    print(f"Real onsets detected: {len(onset_real)}")
    print(f"Model onsets detected: {len(onset_model)}")
    print(f"Matched onsets (Â±{tolerance*1000:.0f}ms): {matched_onsets}")
    print(f"Onset Precision: {onset_precision:.4f} (how many model onsets are correct)")
    print(f"Onset Recall: {onset_recall:.4f} (how many real onsets are detected)")
    print(f"Onset F1-Score: {onset_f1:.4f}")
    print(f"{'='*70}\n")
    
    return {
        'real_onsets_count': int(len(onset_real)),
        'model_onsets_count': int(len(onset_model)),
        'matched_onsets': int(matched_onsets),
        'onset_precision': float(onset_precision),
        'onset_recall': float(onset_recall),
        'onset_f1': float(onset_f1),
        'tolerance_ms': float(tolerance * 1000)
    }


def analyze_spectral_divergence(audio_real, audio_model, sr, source_name):
    """
    åˆ†æé¢‘è°±åˆ†å¸ƒçš„å·®å¼‚ï¼ˆKLæ•£åº¦ï¼‰
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        divergence_stats: æ•£åº¦ç»Ÿè®¡å­—å…¸
    """
    n_fft = 2048
    spec_real = librosa.stft(audio_real, n_fft=n_fft)
    spec_model = librosa.stft(audio_model, n_fft=n_fft)
    
    # è®¡ç®—å¹³å‡é¢‘è°±ï¼ˆå½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼‰
    mag_real = np.abs(spec_real).mean(axis=1)
    mag_model = np.abs(spec_model).mean(axis=1)
    
    # å½’ä¸€åŒ–
    prob_real = mag_real / (mag_real.sum() + 1e-10)
    prob_model = mag_model / (mag_model.sum() + 1e-10)
    
    # KLæ•£åº¦ï¼ˆReal || Modelï¼‰
    kl_div = np.sum(prob_real * np.log((prob_real + 1e-10) / (prob_model + 1e-10)))
    
    # JSæ•£åº¦ï¼ˆå¯¹ç§°ç‰ˆæœ¬ï¼Œæ›´ç¨³å®šï¼‰
    prob_mean = (prob_real + prob_model) / 2
    js_div = 0.5 * np.sum(prob_real * np.log((prob_real + 1e-10) / (prob_mean + 1e-10))) + \
             0.5 * np.sum(prob_model * np.log((prob_model + 1e-10) / (prob_mean + 1e-10)))
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Spectral Divergence Analysis")
    print(f"{'='*70}")
    print(f"KL Divergence: {kl_div:.6f} (0 = identical, lower is better)")
    print(f"JS Divergence: {js_div:.6f} (0 = identical, lower is better)")
    print(f"{'='*70}\n")
    
    return {
        'kl_divergence': float(kl_div),
        'js_divergence': float(js_div)
    }


def analyze_dynamic_range(audio_real, audio_model, sr, source_name):
    """
    åˆ†æåŠ¨æ€èŒƒå›´
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        dynamic_stats: åŠ¨æ€èŒƒå›´ç»Ÿè®¡å­—å…¸
    """
    # è®¡ç®—RMSèƒ½é‡åŒ…ç»œ
    frame_length = 2048
    hop_length = 512
    
    real_rms = librosa.feature.rms(y=audio_real, frame_length=frame_length, hop_length=hop_length)[0]
    model_rms = librosa.feature.rms(y=audio_model, frame_length=frame_length, hop_length=hop_length)[0]
    
    # åŠ¨æ€èŒƒå›´ï¼ˆdBï¼‰
    real_dr = 20 * np.log10(np.max(real_rms) / (np.min(real_rms[real_rms > 0]) + 1e-10))
    model_dr = 20 * np.log10(np.max(model_rms) / (np.min(model_rms[model_rms > 0]) + 1e-10))
    
    # å³°å€¼å’ŒRMS
    real_peak = np.max(np.abs(audio_real))
    model_peak = np.max(np.abs(audio_model))
    real_rms_overall = np.sqrt(np.mean(audio_real ** 2))
    model_rms_overall = np.sqrt(np.mean(audio_model ** 2))
    
    # å³°å€¼å› å­ï¼ˆCrest Factorï¼‰
    real_crest = 20 * np.log10(real_peak / (real_rms_overall + 1e-10))
    model_crest = 20 * np.log10(model_peak / (model_rms_overall + 1e-10))
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Dynamic Range Analysis")
    print(f"{'='*70}")
    print(f"{'Metric':<30} {'Real':<15} {'Model':<15} {'Diff':<15}")
    print(f"{'-'*70}")
    print(f"{'Dynamic Range (dB)':<30} {real_dr:<15.2f} {model_dr:<15.2f} {model_dr-real_dr:<15.2f}")
    print(f"{'Peak Amplitude':<30} {real_peak:<15.4f} {model_peak:<15.4f} {model_peak-real_peak:<15.4f}")
    print(f"{'RMS Amplitude':<30} {real_rms_overall:<15.4f} {model_rms_overall:<15.4f} {model_rms_overall-real_rms_overall:<15.4f}")
    print(f"{'Crest Factor (dB)':<30} {real_crest:<15.2f} {model_crest:<15.2f} {model_crest-real_crest:<15.2f}")
    print(f"{'='*70}\n")
    
    return {
        'real_dynamic_range_db': float(real_dr),
        'model_dynamic_range_db': float(model_dr),
        'real_peak': float(real_peak),
        'model_peak': float(model_peak),
        'real_rms': float(real_rms_overall),
        'model_rms': float(model_rms_overall),
        'real_crest_factor_db': float(real_crest),
        'model_crest_factor_db': float(model_crest)
    }


def analyze_energy_distribution(audio_real, audio_model, sr, source_name):
    """
    åˆ†æçœŸå®æºå’Œæ¨¡å‹è¾“å‡ºåœ¨ä¸åŒé¢‘æ®µçš„èƒ½é‡åˆ†å¸ƒ
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
    
    è¿”å›:
        energy_stats: èƒ½é‡ç»Ÿè®¡å­—å…¸
    """
    # è®¡ç®—STFT
    n_fft = 2048
    spec_real = librosa.stft(audio_real, n_fft=n_fft)
    spec_model = librosa.stft(audio_model, n_fft=n_fft)
    
    # é¢‘ç‡è½´
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    
    # å®šä¹‰é¢‘æ®µ
    bands = {
        'Sub-bass (20-60 Hz)': (20, 60),
        'Bass (60-250 Hz)': (60, 250),
        'Low-mid (250-500 Hz)': (250, 500),
        'Mid (500-2000 Hz)': (500, 2000),
        'High (2000-8000 Hz)': (2000, 8000),
    }
    
    energy_stats = {}
    
    print(f"\n{'='*70}")
    print(f"{source_name.capitalize()} - Energy Distribution Comparison")
    print(f"{'='*70}")
    print(f"{'Frequency Band':<25} {'Real Energy':<15} {'Model Energy':<15} {'Ratio':<10}")
    print(f"{'-'*70}")
    
    for band_name, (f_low, f_high) in bands.items():
        # æ‰¾åˆ°é¢‘æ®µå¯¹åº”çš„bin
        bins = np.where((freqs >= f_low) & (freqs <= f_high))[0]
        
        if len(bins) == 0:
            continue
        
        # è®¡ç®—èƒ½é‡
        energy_real = np.sum(np.abs(spec_real[bins, :]) ** 2)
        energy_model = np.sum(np.abs(spec_model[bins, :]) ** 2)
        
        ratio = energy_model / energy_real if energy_real > 0 else float('inf')
        
        print(f"{band_name:<25} {energy_real:<15.2e} {energy_model:<15.2e} {ratio:<10.3f}")
        
        energy_stats[band_name] = {
            'real_energy': float(energy_real),
            'model_energy': float(energy_model),
            'ratio': float(ratio)
        }
    
    # æ€»èƒ½é‡
    total_energy_real = np.sum(np.abs(spec_real) ** 2)
    total_energy_model = np.sum(np.abs(spec_model) ** 2)
    total_ratio = total_energy_model / total_energy_real if total_energy_real > 0 else float('inf')
    
    print(f"{'-'*70}")
    print(f"{'Total':<25} {total_energy_real:<15.2e} {total_energy_model:<15.2e} {total_ratio:<10.3f}")
    print(f"{'='*70}\n")
    
    energy_stats['Total'] = {
        'real_energy': float(total_energy_real),
        'model_energy': float(total_energy_model),
        'ratio': float(total_ratio)
    }
    
    return energy_stats


def plot_mask_comparison(audio_real, audio_model, sr, source_name, save_path):
    """
    å¯¹æ¯”ç†æƒ³æ©ç å’Œæ¨¡å‹æ©ç 
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    n_fft = 2048
    hop_length = 512
    
    spec_real = librosa.stft(audio_real, n_fft=n_fft, hop_length=hop_length)
    spec_model = librosa.stft(audio_model, n_fft=n_fft, hop_length=hop_length)
    
    # è®¡ç®—æ©ç ï¼ˆå½’ä¸€åŒ–å¹…åº¦ï¼‰
    mag_real = np.abs(spec_real)
    mag_model = np.abs(spec_model)
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    mask_real = mag_real / (np.max(mag_real) + 1e-10)
    mask_model = mag_model / (np.max(mag_model) + 1e-10)
    
    # åˆ›å»ºå›¾å½¢ï¼ˆ2x2ï¼‰
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle(f'{source_name.capitalize()} - Mask Comparison', 
                 fontsize=16, fontweight='bold')
    
    # 1. çœŸå®æºæ©ç 
    img1 = librosa.display.specshow(mask_real, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 0],
                                     cmap='viridis', vmin=0, vmax=1)
    axes[0, 0].set_title('Ideal Mask (Real)', fontsize=12, fontweight='bold')
    axes[0, 0].set_ylabel('Frequency (Hz)')
    axes[0, 0].set_ylim([0, 4000])
    fig.colorbar(img1, ax=axes[0, 0], label='Normalized Magnitude')
    
    # 2. æ¨¡å‹æ©ç 
    img2 = librosa.display.specshow(mask_model, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 1],
                                     cmap='viridis', vmin=0, vmax=1)
    axes[0, 1].set_title('Model Mask', fontsize=12, fontweight='bold')
    axes[0, 1].set_ylabel('Frequency (Hz)')
    axes[0, 1].set_ylim([0, 4000])
    fig.colorbar(img2, ax=axes[0, 1], label='Normalized Magnitude')
    
    # 3. æ©ç è¯¯å·®
    mask_error = mask_model - mask_real
    img3 = librosa.display.specshow(mask_error, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[1, 0],
                                     cmap='RdBu_r', vmin=-1, vmax=1)
    axes[1, 0].set_title('Mask Error (Model - Real)', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('Time (s)')
    axes[1, 0].set_ylabel('Frequency (Hz)')
    axes[1, 0].set_ylim([0, 4000])
    fig.colorbar(img3, ax=axes[1, 0], label='Error')
    
    # 4. æ©ç è¯¯å·®ç›´æ–¹å›¾
    axes[1, 1].hist(mask_error.flatten(), bins=100, alpha=0.7, edgecolor='black', color='steelblue')
    axes[1, 1].set_xlabel('Mask Error')
    axes[1, 1].set_ylabel('Count')
    axes[1, 1].set_title('Mask Error Distribution', fontsize=12, fontweight='bold')
    axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].legend()
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    mean_error = np.mean(mask_error)
    std_error = np.std(mask_error)
    axes[1, 1].text(0.02, 0.98, f'Mean: {mean_error:.4f}\nStd: {std_error:.4f}',
                   transform=axes[1, 1].transAxes, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ æ©ç å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_energy_envelope(audio_real, audio_model, sr, source_name, save_path):
    """
    å¯¹æ¯”èƒ½é‡åŒ…ç»œ
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    frame_length = 2048
    hop_length = 512
    
    real_rms = librosa.feature.rms(y=audio_real, frame_length=frame_length, hop_length=hop_length)[0]
    model_rms = librosa.feature.rms(y=audio_model, frame_length=frame_length, hop_length=hop_length)[0]
    
    times = librosa.frames_to_time(np.arange(len(real_rms)), sr=sr, hop_length=hop_length)
    
    # æ˜¾ç¤ºå…¨æ›²
    duration = times[-1]
    
    fig, axes = plt.subplots(3, 1, figsize=(18, 10))
    fig.suptitle(f'{source_name.capitalize()} - Energy Envelope Comparison (Full Track: {duration:.1f}s)', 
                 fontsize=16, fontweight='bold')
    
    # 1. çœŸå®èƒ½é‡åŒ…ç»œ
    axes[0].fill_between(times, 0, real_rms, alpha=0.7, label='Real', color='steelblue')
    axes[0].set_ylabel('RMS Energy')
    axes[0].set_title('Real Energy Envelope', fontsize=12, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    axes[0].set_xlim([0, duration])
    
    # 2. æ¨¡å‹èƒ½é‡åŒ…ç»œ
    axes[1].fill_between(times, 0, model_rms, alpha=0.7, color='orange', label='Model')
    axes[1].set_ylabel('RMS Energy')
    axes[1].set_title('Model Energy Envelope', fontsize=12, fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    axes[1].legend()
    axes[1].set_xlim([0, duration])
    
    # 3. å åŠ å¯¹æ¯”
    axes[2].plot(times, real_rms, alpha=0.8, label='Real', linewidth=1.5, color='steelblue')
    axes[2].plot(times, model_rms, alpha=0.8, label='Model', linewidth=1.5, color='orange')
    axes[2].fill_between(times, real_rms, model_rms, alpha=0.3, color='gray', label='Difference')
    axes[2].set_xlabel('Time (s)')
    axes[2].set_ylabel('RMS Energy')
    axes[2].set_title('Energy Envelope Comparison', fontsize=12, fontweight='bold')
    axes[2].grid(True, alpha=0.3)
    axes[2].legend()
    axes[2].set_xlim([0, duration])
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ èƒ½é‡åŒ…ç»œå›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_band_energy_evolution(audio_real, audio_model, sr, source_name, save_path):
    """
    å„é¢‘æ®µèƒ½é‡éšæ—¶é—´å˜åŒ–
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    n_fft = 2048
    hop_length = 512
    
    spec_real = librosa.stft(audio_real, n_fft=n_fft, hop_length=hop_length)
    spec_model = librosa.stft(audio_model, n_fft=n_fft, hop_length=hop_length)
    
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    times = librosa.frames_to_time(np.arange(spec_real.shape[1]), sr=sr, hop_length=hop_length)
    
    # å®šä¹‰é¢‘æ®µ
    bands = {
        'Sub-bass (20-60 Hz)': (20, 60),
        'Bass (60-250 Hz)': (60, 250),
        'Low-mid (250-500 Hz)': (250, 500),
        'Mid (500-2000 Hz)': (500, 2000),
        'High (2000-8000 Hz)': (2000, 8000),
    }
    
    # æ˜¾ç¤ºå…¨æ›²
    duration = times[-1]
    
    fig, axes = plt.subplots(len(bands), 1, figsize=(18, 12))
    fig.suptitle(f'{source_name.capitalize()} - Band Energy Evolution (Full Track: {duration:.1f}s)', 
                 fontsize=16, fontweight='bold')
    
    for idx, (band_name, (f_low, f_high)) in enumerate(bands.items()):
        bins = np.where((freqs >= f_low) & (freqs <= f_high))[0]
        
        if len(bins) > 0:
            # è®¡ç®—è¯¥é¢‘æ®µçš„èƒ½é‡éšæ—¶é—´å˜åŒ–
            real_energy = np.sum(np.abs(spec_real[bins, :]) ** 2, axis=0)
            model_energy = np.sum(np.abs(spec_model[bins, :]) ** 2, axis=0)
            
            axes[idx].plot(times, real_energy, alpha=0.8, label='Real', linewidth=1.5, color='steelblue')
            axes[idx].plot(times, model_energy, alpha=0.8, label='Model', linewidth=1.5, color='orange')
            axes[idx].fill_between(times, real_energy, model_energy, alpha=0.2, color='gray')
            axes[idx].set_ylabel('Energy')
            axes[idx].set_title(band_name, fontsize=10, fontweight='bold')
            axes[idx].grid(True, alpha=0.3)
            axes[idx].legend(loc='upper right')
            axes[idx].set_xlim([0, duration])
            
            if idx == len(bands) - 1:
                axes[idx].set_xlabel('Time (s)')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ é¢‘æ®µèƒ½é‡æ¼”åŒ–å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_phase_consistency(audio_real, audio_model, sr, source_name, save_path):
    """
    ç›¸ä½ä¸€è‡´æ€§åˆ†æ
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    n_fft = 2048
    hop_length = 512
    
    spec_real = librosa.stft(audio_real, n_fft=n_fft, hop_length=hop_length)
    spec_model = librosa.stft(audio_model, n_fft=n_fft, hop_length=hop_length)
    
    # è®¡ç®—ç›¸ä½å·®
    phase_real = np.angle(spec_real)
    phase_model = np.angle(spec_model)
    phase_diff = np.angle(np.exp(1j * (phase_model - phase_real)))  # å½’ä¸€åŒ–åˆ°[-Ï€, Ï€]
    
    # è®¡ç®—ç›¸ä½ä¸€è‡´æ€§ï¼ˆä½™å¼¦ï¼‰
    phase_consistency = np.cos(phase_diff)
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle(f'{source_name.capitalize()} - Phase Consistency Analysis', 
                 fontsize=16, fontweight='bold')
    
    # 1. çœŸå®ç›¸ä½
    img1 = librosa.display.specshow(phase_real, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 0],
                                     cmap='twilight', vmin=-np.pi, vmax=np.pi)
    axes[0, 0].set_title('Real Phase', fontsize=12, fontweight='bold')
    axes[0, 0].set_ylabel('Frequency (Hz)')
    axes[0, 0].set_ylim([0, 4000])
    fig.colorbar(img1, ax=axes[0, 0], label='Phase (rad)')
    
    # 2. æ¨¡å‹ç›¸ä½
    img2 = librosa.display.specshow(phase_model, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[0, 1],
                                     cmap='twilight', vmin=-np.pi, vmax=np.pi)
    axes[0, 1].set_title('Model Phase', fontsize=12, fontweight='bold')
    axes[0, 1].set_ylabel('Frequency (Hz)')
    axes[0, 1].set_ylim([0, 4000])
    fig.colorbar(img2, ax=axes[0, 1], label='Phase (rad)')
    
    # 3. ç›¸ä½å·®
    img3 = librosa.display.specshow(phase_diff, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[1, 0],
                                     cmap='RdBu_r', vmin=-np.pi, vmax=np.pi)
    axes[1, 0].set_title('Phase Difference', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('Time (s)')
    axes[1, 0].set_ylabel('Frequency (Hz)')
    axes[1, 0].set_ylim([0, 4000])
    fig.colorbar(img3, ax=axes[1, 0], label='Phase Diff (rad)')
    
    # 4. ç›¸ä½ä¸€è‡´æ€§
    img4 = librosa.display.specshow(phase_consistency, sr=sr, hop_length=hop_length,
                                     x_axis='time', y_axis='hz', ax=axes[1, 1],
                                     cmap='viridis', vmin=-1, vmax=1)
    axes[1, 1].set_title('Phase Consistency (cos)', fontsize=12, fontweight='bold')
    axes[1, 1].set_xlabel('Time (s)')
    axes[1, 1].set_ylabel('Frequency (Hz)')
    axes[1, 1].set_ylim([0, 4000])
    fig.colorbar(img4, ax=axes[1, 1], label='Consistency')
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    mean_consistency = np.mean(phase_consistency)
    axes[1, 1].text(0.02, 0.98, f'Mean Consistency: {mean_consistency:.4f}',
                   transform=axes[1, 1].transAxes, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ ç›¸ä½ä¸€è‡´æ€§å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_waveform_comparison(audio_real, audio_model, sr, source_name, save_path):
    """
    å¯¹æ¯”çœŸå®æºå’Œæ¨¡å‹è¾“å‡ºçš„æ³¢å½¢
    
    å‚æ•°:
        audio_real: çœŸå®æºéŸ³é¢‘
        audio_model: æ¨¡å‹è¾“å‡ºéŸ³é¢‘
        sr: é‡‡æ ·ç‡
        source_name: æºåç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    # æ˜¾ç¤ºæ•´é¦–æ­Œï¼Œä½†é™é‡‡æ ·ä»¥ä¾¿å¯è§†åŒ–
    # å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œæ¯éš”Nä¸ªæ ·æœ¬å–ä¸€ä¸ªç‚¹
    max_points = 100000  # æœ€å¤šæ˜¾ç¤º10ä¸‡ä¸ªç‚¹
    total_samples = len(audio_real)
    
    if total_samples > max_points:
        # é™é‡‡æ ·
        step = total_samples // max_points
        audio_real_short = audio_real[::step]
        audio_model_short = audio_model[::step]
        duration = total_samples / sr
        time = np.linspace(0, duration, len(audio_real_short))
    else:
        # ç›´æ¥æ˜¾ç¤ºå…¨éƒ¨
        audio_real_short = audio_real
        audio_model_short = audio_model
        duration = total_samples / sr
        time = np.linspace(0, duration, total_samples)
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(3, 1, figsize=(18, 10))
    fig.suptitle(f'{source_name.capitalize()} - Waveform Comparison (Full Track: {duration:.1f}s)', 
                 fontsize=16, fontweight='bold')
    
    # 1. çœŸå®æºæ³¢å½¢
    axes[0].plot(time, audio_real_short, linewidth=0.3, alpha=0.8)
    axes[0].set_title('Real (Ground Truth)', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Amplitude')
    axes[0].grid(True, alpha=0.3)
    axes[0].set_xlim([0, duration])
    
    # 2. æ¨¡å‹è¾“å‡ºæ³¢å½¢
    axes[1].plot(time, audio_model_short, linewidth=0.3, alpha=0.8, color='orange')
    axes[1].set_title(f'{MODEL_NAME} (Predicted)', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Amplitude')
    axes[1].grid(True, alpha=0.3)
    axes[1].set_xlim([0, duration])
    
    # 3. å·®å¼‚ï¼ˆè¯¯å·®ï¼‰
    diff = audio_model_short - audio_real_short
    axes[2].plot(time, diff, linewidth=0.3, alpha=0.8, color='red')
    axes[2].set_title('Error (Model - Real)', fontsize=12, fontweight='bold')
    axes[2].set_xlabel('Time (s)')
    axes[2].set_ylabel('Amplitude')
    axes[2].grid(True, alpha=0.3)
    axes[2].set_xlim([0, duration])
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ æ³¢å½¢å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_all_sources_comparison(real_dir, separated_model, track_name, output_dir):
    """
    ç”Ÿæˆæ‰€æœ‰æºçš„ç»¼åˆå¯¹æ¯”å›¾
    
    å‚æ•°:
        real_dir: çœŸå®æºç›®å½•
        separated_model: æ¨¡å‹åˆ†ç¦»ç»“æœç›®å½•
        track_name: æ­Œæ›²åç§°
        output_dir: è¾“å‡ºç›®å½•
    """
    sources = SOURCES
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('All Sources - Frequency Profile Comparison (Real vs Model)', 
                 fontsize=16, fontweight='bold')
    
    axes = axes.flatten()
    
    for idx, source_name in enumerate(sources):
        # åŠ è½½éŸ³é¢‘
        try:
            audio_real, sr = load_source_audio(real_dir, source_name, is_real=True)
            audio_model, _ = load_source_audio(separated_model, source_name, is_real=False)
        except FileNotFoundError:
            continue
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(audio_real), len(audio_model))
        audio_real = audio_real[:min_len]
        audio_model = audio_model[:min_len]
        
        # è®¡ç®—STFT
        n_fft = 2048
        spec_real = librosa.stft(audio_real, n_fft=n_fft)
        spec_model = librosa.stft(audio_model, n_fft=n_fft)
        
        # è®¡ç®—å¹³å‡é¢‘è°±
        mag_real = np.abs(spec_real).mean(axis=1)
        mag_model = np.abs(spec_model).mean(axis=1)
        freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
        
        # ç»˜åˆ¶
        ax = axes[idx]
        ax.plot(freqs, 20*np.log10(mag_real + 1e-10), 
               label='Real', linewidth=2, alpha=0.8)
        ax.plot(freqs, 20*np.log10(mag_model + 1e-10), 
               label=MODEL_NAME, linewidth=2, alpha=0.8)
        ax.set_xlim([0, 2000])
        ax.set_xlabel('Frequency (Hz)')
        ax.set_ylabel('Magnitude (dB)')
        ax.set_title(source_name.capitalize(), fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ ‡æ³¨ç‰¹å®šé¢‘æ®µ
        if source_name == 'bass':
            ax.axvspan(40, 250, alpha=0.2, color='red', label='Bass Range')
        elif source_name == 'drums':
            ax.axvspan(50, 500, alpha=0.2, color='orange', label='Drums Range')
    
    plt.tight_layout()
    
    save_path = output_dir / "all_sources.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ ç»¼åˆå¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    plt.close()


def generate_markdown_report(all_stats, output_dir, track_name):
    """
    ç”Ÿæˆæ˜“è¯»çš„MarkdownæŠ¥å‘Š
    
    å‚æ•°:
        all_stats: æ‰€æœ‰ç»Ÿè®¡æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
        track_name: æ­Œæ›²åç§°
    """
    report_path = output_dir / "report.md"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        # æ ‡é¢˜
        f.write(f"# Audio Separation Analysis Report\n\n")
        f.write(f"**Model**: {all_stats['model']}\n\n")
        f.write(f"**Track**: {all_stats['track']}\n\n")
        f.write(f"**Analysis Time**: {all_stats['timestamp']}\n\n")
        f.write("---\n\n")
        
        # ä¸ºæ¯ä¸ªæºç”ŸæˆæŠ¥å‘Š
        for source_name in SOURCES:
            if source_name not in all_stats['sources']:
                continue
            
            source_data = all_stats['sources'][source_name]
            
            f.write(f"## {source_name.capitalize()}\n\n")
            f.write(f"**Duration**: {source_data['duration_seconds']:.2f} seconds\n\n")
            f.write(f"**Sample Rate**: {source_data['sample_rate']} Hz\n\n")
            
            # 1. èƒ½é‡åˆ†å¸ƒ
            f.write("### 1. Energy Distribution\n\n")
            f.write("| Frequency Band | Real Energy | Model Energy | Ratio | Status |\n")
            f.write("|---|---|---|---|---|\n")
            
            energy_dist = source_data['energy_distribution']
            for band_name, band_data in energy_dist.items():
                ratio = band_data['ratio']
                if ratio > 1.1:
                    status = "âš ï¸ Over-extraction"
                elif ratio < 0.9:
                    status = "âš ï¸ Under-extraction"
                else:
                    status = "âœ… Good"
                
                f.write(f"| {band_name} | {band_data['real_energy']:.2e} | {band_data['model_energy']:.2e} | {ratio:.3f} | {status} |\n")
            
            f.write("\n")
            
            # 2. é¢‘è°±ç›¸ä¼¼åº¦
            f.write("### 2. Spectral Similarity\n\n")
            similarity = source_data['spectral_similarity']
            f.write(f"- **Overall Correlation**: {similarity['overall_correlation']:.4f} (1.0 = perfect)\n")
            f.write(f"- **Cosine Similarity**: {similarity['cosine_similarity']:.4f} (1.0 = perfect)\n\n")
            
            f.write("**Band-wise Correlations**:\n\n")
            for band_name, corr in similarity['band_correlations'].items():
                status = "âœ…" if corr > 0.9 else "âš ï¸" if corr > 0.7 else "âŒ"
                f.write(f"- {band_name}: {corr:.4f} {status}\n")
            f.write("\n")
            
            # 3. è¯¯å·®èƒ½é‡ï¼ˆPseudo-SDRï¼‰
            f.write("### 3. Error Energy (Pseudo-SDR)\n\n")
            f.write("| Frequency Band | Pseudo-SDR (dB) | Error Ratio | Quality |\n")
            f.write("|---|---|---|---|\n")
            
            error_energy = source_data['error_energy']
            for band_name, band_data in error_energy.items():
                sdr = band_data['pseudo_sdr']
                if sdr > 10:
                    quality = "âœ… Excellent"
                elif sdr > 5:
                    quality = "ğŸ‘ Good"
                elif sdr > 0:
                    quality = "âš ï¸ Fair"
                else:
                    quality = "âŒ Poor"
                
                f.write(f"| {band_name} | {sdr:.2f} | {band_data['error_ratio']:.4f} | {quality} |\n")
            
            f.write("\n")
            
            # 4. é™éŸ³æ®µæ³„æ¼
            f.write("### 4. Silence Leakage\n\n")
            leakage = source_data['silence_leakage']
            f.write(f"- **Silence Frames**: {leakage['silence_frames_count']} / {leakage['total_frames']} ({leakage['silence_frames_percentage']:.1f}%)\n")
            f.write(f"- **Leakage Ratio**: {leakage['leakage_ratio']:.4f} (lower is better)\n")
            f.write(f"- **Silence Energy Ratio**: {leakage['silence_energy_ratio']:.4f} ({leakage['silence_energy_ratio']*100:.2f}% of total output)\n")
            
            if leakage['leakage_ratio'] < 0.1:
                f.write(f"- **Status**: âœ… Minimal leakage\n")
            elif leakage['leakage_ratio'] < 0.3:
                f.write(f"- **Status**: âš ï¸ Moderate leakage\n")
            else:
                f.write(f"- **Status**: âŒ Significant leakage\n")
            f.write("\n")
            
            # 5. æ—¶é—´å¯¹é½
            f.write("### 5. Temporal Alignment (Onset Detection)\n\n")
            temporal = source_data['temporal_alignment']
            f.write(f"- **Real Onsets**: {temporal['real_onsets_count']}\n")
            f.write(f"- **Model Onsets**: {temporal['model_onsets_count']}\n")
            f.write(f"- **Matched Onsets**: {temporal['matched_onsets']} (Â±{temporal['tolerance_ms']:.0f}ms)\n")
            f.write(f"- **Precision**: {temporal['onset_precision']:.4f} (how many model onsets are correct)\n")
            f.write(f"- **Recall**: {temporal['onset_recall']:.4f} (how many real onsets are detected)\n")
            f.write(f"- **F1-Score**: {temporal['onset_f1']:.4f}\n")
            
            if temporal['onset_f1'] > 0.8:
                f.write(f"- **Status**: âœ… Excellent temporal alignment\n")
            elif temporal['onset_f1'] > 0.6:
                f.write(f"- **Status**: ğŸ‘ Good temporal alignment\n")
            else:
                f.write(f"- **Status**: âš ï¸ Poor temporal alignment\n")
            f.write("\n")
            
            # 6. é¢‘è°±æ•£åº¦
            f.write("### 6. Spectral Divergence\n\n")
            divergence = source_data['spectral_divergence']
            f.write(f"- **KL Divergence**: {divergence['kl_divergence']:.6f} (0 = identical)\n")
            f.write(f"- **JS Divergence**: {divergence['js_divergence']:.6f} (0 = identical)\n\n")
            
            # 7. åŠ¨æ€èŒƒå›´
            f.write("### 7. Dynamic Range\n\n")
            f.write("| Metric | Real | Model | Difference |\n")
            f.write("|---|---|---|---|\n")
            
            dynamic = source_data['dynamic_range']
            f.write(f"| Dynamic Range (dB) | {dynamic['real_dynamic_range_db']:.2f} | {dynamic['model_dynamic_range_db']:.2f} | {dynamic['model_dynamic_range_db']-dynamic['real_dynamic_range_db']:.2f} |\n")
            f.write(f"| Peak Amplitude | {dynamic['real_peak']:.4f} | {dynamic['model_peak']:.4f} | {dynamic['model_peak']-dynamic['real_peak']:.4f} |\n")
            f.write(f"| RMS Amplitude | {dynamic['real_rms']:.4f} | {dynamic['model_rms']:.4f} | {dynamic['model_rms']-dynamic['real_rms']:.4f} |\n")
            f.write(f"| Crest Factor (dB) | {dynamic['real_crest_factor_db']:.2f} | {dynamic['model_crest_factor_db']:.2f} | {dynamic['model_crest_factor_db']-dynamic['real_crest_factor_db']:.2f} |\n")
            
            f.write("\n---\n\n")
        
        # æ€»ç»“
        f.write("## Summary\n\n")
        f.write("### Overall Assessment\n\n")
        
        # è®¡ç®—å„æºçš„æ€»ä½“è¯„åˆ†
        for source_name in SOURCES:
            if source_name not in all_stats['sources']:
                continue
            
            source_data = all_stats['sources'][source_name]
            
            # ç®€å•è¯„åˆ†ç³»ç»Ÿ
            score = 0
            total = 0
            
            # èƒ½é‡æ¯”æ¥è¿‘1
            energy_ratio = source_data['energy_distribution']['Total']['ratio']
            if 0.9 <= energy_ratio <= 1.1:
                score += 2
            elif 0.8 <= energy_ratio <= 1.2:
                score += 1
            total += 2
            
            # ç›¸å…³ç³»æ•°é«˜
            corr = source_data['spectral_similarity']['overall_correlation']
            if corr > 0.9:
                score += 2
            elif corr > 0.7:
                score += 1
            total += 2
            
            # Pseudo-SDRé«˜
            pseudo_sdr = source_data['error_energy']['Total']['pseudo_sdr']
            if pseudo_sdr > 10:
                score += 2
            elif pseudo_sdr > 5:
                score += 1
            total += 2
            
            # æ³„æ¼ä½
            leakage_ratio = source_data['silence_leakage']['leakage_ratio']
            if leakage_ratio < 0.1:
                score += 2
            elif leakage_ratio < 0.3:
                score += 1
            total += 2
            
            # Onset F1é«˜
            onset_f1 = source_data['temporal_alignment']['onset_f1']
            if onset_f1 > 0.8:
                score += 2
            elif onset_f1 > 0.6:
                score += 1
            total += 2
            
            percentage = (score / total) * 100
            
            if percentage >= 80:
                rating = "âœ… Excellent"
            elif percentage >= 60:
                rating = "ğŸ‘ Good"
            elif percentage >= 40:
                rating = "âš ï¸ Fair"
            else:
                rating = "âŒ Poor"
            
            f.write(f"- **{source_name.capitalize()}**: {percentage:.0f}% {rating}\n")
        
        f.write("\n")
        f.write("### Generated Visualizations\n\n")
        f.write(f"- Spectrum comparison: {len(SOURCES)} images\n")
        f.write(f"- Waveform comparison: {len(SOURCES)} images\n")
        f.write(f"- Mask comparison: {len(SOURCES)} images\n")
        f.write(f"- Energy envelope: {len(SOURCES)} images\n")
        f.write(f"- Band energy evolution: {len(SOURCES)} images\n")
        f.write(f"- Phase consistency: {len(SOURCES)} images\n")
        f.write(f"- Comprehensive comparison: 1 image\n")
        f.write(f"\n**Total**: {len(SOURCES)*6 + 1} images\n")
    
    print(f"âœ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    return report_path


def generate_html_report(all_stats, output_dir, track_name):
    """
    ç”ŸæˆHTMLå¯è§†åŒ–æŠ¥å‘Š
    
    å‚æ•°:
        all_stats: æ‰€æœ‰ç»Ÿè®¡æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
        track_name: æ­Œæ›²åç§°
    """
    report_path = output_dir / "report.html"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        # HTMLå¤´éƒ¨
        f.write("""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Separation Analysis Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
        }
        .header h1 {
            margin: 0 0 10px 0;
        }
        .header p {
            margin: 5px 0;
            opacity: 0.9;
        }
        .source-section {
            background: white;
            padding: 25px;
            margin-bottom: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .source-section h2 {
            color: #667eea;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin-top: 0;
        }
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .metric-card {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        .metric-card h4 {
            margin: 0 0 10px 0;
            color: #333;
            font-size: 14px;
        }
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #667eea;
        }
        .metric-label {
            font-size: 12px;
            color: #666;
            margin-top: 5px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #667eea;
            color: white;
            font-weight: 600;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .status-excellent { color: #28a745; font-weight: bold; }
        .status-good { color: #17a2b8; font-weight: bold; }
        .status-fair { color: #ffc107; font-weight: bold; }
        .status-poor { color: #dc3545; font-weight: bold; }
        .summary {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 25px;
            border-radius: 10px;
            margin-top: 30px;
        }
        .summary h2 {
            margin-top: 0;
        }
        .score-bar {
            background: rgba(255,255,255,0.3);
            height: 30px;
            border-radius: 15px;
            overflow: hidden;
            margin: 10px 0;
        }
        .score-fill {
            background: white;
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            transition: width 0.5s ease;
        }
    </style>
</head>
<body>
""")
        
        # æ ‡é¢˜éƒ¨åˆ†
        f.write(f"""
    <div class="header">
        <h1>ğŸµ Audio Separation Analysis Report</h1>
        <p><strong>Model:</strong> {all_stats['model']}</p>
        <p><strong>Track:</strong> {all_stats['track']}</p>
        <p><strong>Analysis Time:</strong> {all_stats['timestamp']}</p>
    </div>
""")
        
        # ä¸ºæ¯ä¸ªæºç”ŸæˆæŠ¥å‘Š
        for source_name in SOURCES:
            if source_name not in all_stats['sources']:
                continue
            
            source_data = all_stats['sources'][source_name]
            
            # æºæ ‡é¢˜
            emoji_map = {'drums': 'ğŸ¥', 'bass': 'ğŸ¸', 'other': 'ğŸ¹', 'vocals': 'ğŸ¤'}
            emoji = emoji_map.get(source_name, 'ğŸµ')
            
            f.write(f"""
    <div class="source-section">
        <h2>{emoji} {source_name.capitalize()}</h2>
        <p><strong>Duration:</strong> {source_data['duration_seconds']:.2f}s | <strong>Sample Rate:</strong> {source_data['sample_rate']} Hz</p>
""")
            
            # å…³é”®æŒ‡æ ‡å¡ç‰‡
            similarity = source_data['spectral_similarity']
            error_energy = source_data['error_energy']
            leakage = source_data['silence_leakage']
            temporal = source_data['temporal_alignment']
            
            f.write("""
        <div class="metric-grid">
""")
            
            f.write(f"""
            <div class="metric-card">
                <h4>Spectral Correlation</h4>
                <div class="metric-value">{similarity['overall_correlation']:.3f}</div>
                <div class="metric-label">1.0 = perfect match</div>
            </div>
            <div class="metric-card">
                <h4>Pseudo-SDR</h4>
                <div class="metric-value">{error_energy['Total']['pseudo_sdr']:.2f} dB</div>
                <div class="metric-label">Higher is better</div>
            </div>
            <div class="metric-card">
                <h4>Silence Leakage</h4>
                <div class="metric-value">{leakage['leakage_ratio']:.3f}</div>
                <div class="metric-label">Lower is better</div>
            </div>
            <div class="metric-card">
                <h4>Onset F1-Score</h4>
                <div class="metric-value">{temporal['onset_f1']:.3f}</div>
                <div class="metric-label">Temporal accuracy</div>
            </div>
""")
            
            f.write("""
        </div>
""")
            
            # èƒ½é‡åˆ†å¸ƒè¡¨æ ¼
            f.write("""
        <h3>Energy Distribution</h3>
        <table>
            <tr>
                <th>Frequency Band</th>
                <th>Real Energy</th>
                <th>Model Energy</th>
                <th>Ratio</th>
                <th>Status</th>
            </tr>
""")
            
            energy_dist = source_data['energy_distribution']
            for band_name, band_data in energy_dist.items():
                ratio = band_data['ratio']
                if ratio > 1.1:
                    status = '<span class="status-fair">âš ï¸ Over</span>'
                elif ratio < 0.9:
                    status = '<span class="status-fair">âš ï¸ Under</span>'
                else:
                    status = '<span class="status-excellent">âœ… Good</span>'
                
                f.write(f"""
            <tr>
                <td>{band_name}</td>
                <td>{band_data['real_energy']:.2e}</td>
                <td>{band_data['model_energy']:.2e}</td>
                <td>{ratio:.3f}</td>
                <td>{status}</td>
            </tr>
""")
            
            f.write("""
        </table>
""")
            
            f.write("""
    </div>
""")
        
        # æ€»ç»“éƒ¨åˆ†
        f.write("""
    <div class="summary">
        <h2>ğŸ“Š Overall Assessment</h2>
""")
        
        for source_name in SOURCES:
            if source_name not in all_stats['sources']:
                continue
            
            source_data = all_stats['sources'][source_name]
            
            # è®¡ç®—è¯„åˆ†
            score = 0
            total = 10
            
            energy_ratio = source_data['energy_distribution']['Total']['ratio']
            if 0.9 <= energy_ratio <= 1.1:
                score += 2
            elif 0.8 <= energy_ratio <= 1.2:
                score += 1
            
            corr = source_data['spectral_similarity']['overall_correlation']
            if corr > 0.9:
                score += 2
            elif corr > 0.7:
                score += 1
            
            pseudo_sdr = source_data['error_energy']['Total']['pseudo_sdr']
            if pseudo_sdr > 10:
                score += 2
            elif pseudo_sdr > 5:
                score += 1
            
            leakage_ratio = source_data['silence_leakage']['leakage_ratio']
            if leakage_ratio < 0.1:
                score += 2
            elif leakage_ratio < 0.3:
                score += 1
            
            onset_f1 = source_data['temporal_alignment']['onset_f1']
            if onset_f1 > 0.8:
                score += 2
            elif onset_f1 > 0.6:
                score += 1
            
            percentage = (score / total) * 100
            
            if percentage >= 80:
                rating = "âœ… Excellent"
            elif percentage >= 60:
                rating = "ğŸ‘ Good"
            elif percentage >= 40:
                rating = "âš ï¸ Fair"
            else:
                rating = "âŒ Poor"
            
            f.write(f"""
        <h3>{source_name.capitalize()}: {rating}</h3>
        <div class="score-bar">
            <div class="score-fill" style="width: {percentage}%;">{percentage:.0f}%</div>
        </div>
""")
        
        f.write("""
    </div>
""")
        
        # HTMLå°¾éƒ¨
        f.write("""
</body>
</html>
""")
    
    print(f"âœ“ HTMLæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    return report_path


def main():
    """
    ä¸»å‡½æ•°
    """
    print("="*70)
    print("æ¨¡å‹ vs çœŸå®æº é¢‘è°±å¯¹æ¯”åˆ†æ")
    print("="*70)
    print(f"æ¨¡å‹: {MODEL_NAME}")
    print(f"MUSDBæ­Œæ›²ç›®å½•: {MUSDB_TRACK_DIR}")
    print(f"æº: {', '.join(SOURCES)}")
    print("="*70)
    
    # æ£€æŸ¥MUSDBç›®å½•æ˜¯å¦å­˜åœ¨
    track_dir = Path(MUSDB_TRACK_DIR)
    if not track_dir.exists():
        print(f"âœ— é”™è¯¯: æ‰¾ä¸åˆ°MUSDBæ­Œæ›²ç›®å½• {MUSDB_TRACK_DIR}")
        sys.exit(1)
    
    track_name = track_dir.name
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŒ…å«æ¨¡å‹åå­æ–‡ä»¶å¤¹ï¼‰
    output_dir = Path(OUTPUT_DIR) / MODEL_NAME
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. æ£€æŸ¥å¹¶ç”Ÿæˆæ¨¡å‹çš„åˆ†ç¦»ç»“æœ
    print(f"\n[1/1] æ£€æŸ¥ {MODEL_NAME} æ¨¡å‹çš„åˆ†ç¦»ç»“æœ...")
    separated_model = check_and_generate_separation(MODEL_NAME, track_dir)
    
    # ç”¨äºä¿å­˜æ‰€æœ‰æ•°å€¼ç»“æœ
    all_stats = {
        'model': MODEL_NAME,
        'track': track_name,
        'timestamp': datetime.now().isoformat(),
        'sources': {}
    }
    
    # 2. å¯¹æ¯ä¸ªæºè¿›è¡Œåˆ†æ
    for idx, source_name in enumerate(SOURCES, 1):
        print(f"\n{'='*70}")
        print(f"[{idx}/{len(SOURCES)}] åˆ†æ {source_name.upper()}")
        print(f"{'='*70}")
        
        # åŠ è½½éŸ³é¢‘
        print(f"åŠ è½½éŸ³é¢‘...")
        try:
            audio_real, sr_real = load_source_audio(track_dir, source_name, is_real=True)
            audio_model, sr_model = load_source_audio(separated_model, source_name, is_real=False)
        except FileNotFoundError as e:
            print(f"âœ— é”™è¯¯: {e}")
            continue
        
        if sr_real != sr_model:
            print(f"âœ— é”™è¯¯: é‡‡æ ·ç‡ä¸åŒ¹é… ({sr_real} vs {sr_model})")
            continue
        
        sr = sr_real
        print(f"  é‡‡æ ·ç‡: {sr} Hz")
        print(f"  Realæ—¶é•¿: {len(audio_real)/sr:.2f} ç§’")
        print(f"  Modelæ—¶é•¿: {len(audio_model)/sr:.2f} ç§’")
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(audio_real), len(audio_model))
        audio_real = audio_real[:min_len]
        audio_model = audio_model[:min_len]
        
        # ç”Ÿæˆé¢‘è°±å¯¹æ¯”å›¾
        print(f"ç”Ÿæˆé¢‘è°±å¯¹æ¯”å›¾...")
        spectrum_path = output_dir / f"{source_name}_spectrum.png"
        plot_spectrum_comparison(audio_real, audio_model, sr, source_name, spectrum_path)
        
        # ç”Ÿæˆæ³¢å½¢å¯¹æ¯”å›¾
        print(f"ç”Ÿæˆæ³¢å½¢å¯¹æ¯”å›¾...")
        waveform_path = output_dir / f"{source_name}_waveform.png"
        plot_waveform_comparison(audio_real, audio_model, sr, source_name, waveform_path)
        
        # ç”Ÿæˆæ©ç å¯¹æ¯”å›¾
        print(f"ç”Ÿæˆæ©ç å¯¹æ¯”å›¾...")
        mask_path = output_dir / f"{source_name}_mask.png"
        plot_mask_comparison(audio_real, audio_model, sr, source_name, mask_path)
        
        # ç”Ÿæˆèƒ½é‡åŒ…ç»œå›¾
        print(f"ç”Ÿæˆèƒ½é‡åŒ…ç»œå›¾...")
        envelope_path = output_dir / f"{source_name}_envelope.png"
        plot_energy_envelope(audio_real, audio_model, sr, source_name, envelope_path)
        
        # ç”Ÿæˆé¢‘æ®µèƒ½é‡æ¼”åŒ–å›¾
        print(f"ç”Ÿæˆé¢‘æ®µèƒ½é‡æ¼”åŒ–å›¾...")
        band_evolution_path = output_dir / f"{source_name}_band_evolution.png"
        plot_band_energy_evolution(audio_real, audio_model, sr, source_name, band_evolution_path)
        
        # ç”Ÿæˆç›¸ä½ä¸€è‡´æ€§å›¾
        print(f"ç”Ÿæˆç›¸ä½ä¸€è‡´æ€§å›¾...")
        phase_path = output_dir / f"{source_name}_phase.png"
        plot_phase_consistency(audio_real, audio_model, sr, source_name, phase_path)
        
        # åˆ†æèƒ½é‡åˆ†å¸ƒ
        print(f"åˆ†æèƒ½é‡åˆ†å¸ƒ...")
        energy_stats = analyze_energy_distribution(audio_real, audio_model, sr, source_name)
        
        # åˆ†æé¢‘è°±ç›¸ä¼¼åº¦
        print(f"åˆ†æé¢‘è°±ç›¸ä¼¼åº¦...")
        similarity_stats = analyze_spectral_similarity(audio_real, audio_model, sr, source_name)
        
        # åˆ†æè¯¯å·®èƒ½é‡
        print(f"åˆ†æè¯¯å·®èƒ½é‡...")
        error_stats = analyze_error_energy(audio_real, audio_model, sr, source_name)
        
        # åˆ†æé™éŸ³æ®µæ³„æ¼
        print(f"åˆ†æé™éŸ³æ®µæ³„æ¼...")
        leakage_stats = analyze_silence_leakage(audio_real, audio_model, sr, source_name)
        
        # åˆ†ææ—¶é—´å¯¹é½
        print(f"åˆ†ææ—¶é—´å¯¹é½...")
        temporal_stats = analyze_temporal_alignment(audio_real, audio_model, sr, source_name)
        
        # åˆ†æé¢‘è°±æ•£åº¦
        print(f"åˆ†æé¢‘è°±æ•£åº¦...")
        divergence_stats = analyze_spectral_divergence(audio_real, audio_model, sr, source_name)
        
        # åˆ†æåŠ¨æ€èŒƒå›´
        print(f"åˆ†æåŠ¨æ€èŒƒå›´...")
        dynamic_stats = analyze_dynamic_range(audio_real, audio_model, sr, source_name)
        
        # ä¿å­˜åˆ°ç»Ÿè®¡å­—å…¸
        all_stats['sources'][source_name] = {
            'sample_rate': sr,
            'duration_seconds': float(min_len / sr),
            'energy_distribution': energy_stats,
            'spectral_similarity': similarity_stats,
            'error_energy': error_stats,
            'silence_leakage': leakage_stats,
            'temporal_alignment': temporal_stats,
            'spectral_divergence': divergence_stats,
            'dynamic_range': dynamic_stats
        }
    
    # 3. ç”Ÿæˆç»¼åˆå¯¹æ¯”å›¾ï¼ˆæ‰€æœ‰æºçš„é¢‘ç‡å‰–é¢ï¼‰
    print(f"\n{'='*70}")
    print("ç”Ÿæˆç»¼åˆå¯¹æ¯”å›¾...")
    print(f"{'='*70}")
    plot_all_sources_comparison(track_dir, separated_model, track_name, output_dir)
    
    # 4. ä¿å­˜æ•°å€¼ç»“æœåˆ°JSONæ–‡ä»¶
    stats_file = output_dir / "analysis_data.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(all_stats, f, indent=2, ensure_ascii=False)
    print(f"âœ“ èƒ½é‡ç»Ÿè®¡æ•°æ®å·²ä¿å­˜: {stats_file}")
    
    # 5. ç”ŸæˆMarkdownæŠ¥å‘Š
    print(f"\n{'='*70}")
    print("ç”Ÿæˆæ˜“è¯»æŠ¥å‘Š...")
    print(f"{'='*70}")
    markdown_report = generate_markdown_report(all_stats, output_dir, track_name)
    
    # 6. ç”ŸæˆHTMLæŠ¥å‘Š
    html_report = generate_html_report(all_stats, output_dir, track_name)
    
    print(f"\n{'='*70}")
    print("âœ“ å…¨éƒ¨åˆ†æå®Œæˆï¼")
    print(f"ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"\nç”Ÿæˆçš„å›¾è¡¨:")
    print(f"  - é¢‘è°±å¯¹æ¯”å›¾: {len(SOURCES)}å¼ ")
    print(f"  - æ³¢å½¢å¯¹æ¯”å›¾: {len(SOURCES)}å¼ ")
    print(f"  - æ©ç å¯¹æ¯”å›¾: {len(SOURCES)}å¼  (NEW)")
    print(f"  - èƒ½é‡åŒ…ç»œå›¾: {len(SOURCES)}å¼  (NEW)")
    print(f"  - é¢‘æ®µèƒ½é‡æ¼”åŒ–å›¾: {len(SOURCES)}å¼  (NEW)")
    print(f"  - ç›¸ä½ä¸€è‡´æ€§å›¾: {len(SOURCES)}å¼  (NEW)")
    print(f"  - ç»¼åˆå¯¹æ¯”å›¾: 1å¼ ")
    print(f"\nç”Ÿæˆçš„æŠ¥å‘Š:")
    print(f"  - JSONæ•°æ®æ–‡ä»¶: 1ä¸ª (æœºå™¨å¯è¯»)")
    print(f"  - MarkdownæŠ¥å‘Š: 1ä¸ª (æ˜“è¯»æ–‡æœ¬)")
    print(f"  - HTMLæŠ¥å‘Š: 1ä¸ª (å¯è§†åŒ–ç½‘é¡µ)")
    print(f"\nåˆ†ææŒ‡æ ‡åŒ…æ‹¬:")
    print(f"  1. èƒ½é‡åˆ†å¸ƒ (å„é¢‘æ®µèƒ½é‡å¯¹æ¯”)")
    print(f"  2. é¢‘è°±ç›¸ä¼¼åº¦ (ç›¸å…³ç³»æ•°ã€ä½™å¼¦ç›¸ä¼¼åº¦)")
    print(f"  3. è¯¯å·®èƒ½é‡ (Pseudo-SDR)")
    print(f"  4. é™éŸ³æ®µæ³„æ¼ (æ³„æ¼æ¯”ä¾‹)")
    print(f"  5. æ—¶é—´å¯¹é½ (Onsetæ£€æµ‹)")
    print(f"  6. é¢‘è°±æ•£åº¦ (KL/JSæ•£åº¦)")
    print(f"  7. åŠ¨æ€èŒƒå›´ (å³°å€¼ã€RMSã€Crest Factor)")
    print(f"\n  æ€»è®¡: {len(SOURCES)*6 + 1}å¼ å›¾ + 3ä¸ªæŠ¥å‘Šæ–‡ä»¶ + 7ç±»åˆ†ææŒ‡æ ‡")
    print("="*70)


if __name__ == "__main__":
    main()
