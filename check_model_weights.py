#!/usr/bin/env python3
"""
é€šç”¨è„šæœ¬ï¼šæ£€æŸ¥å¤šåˆ†è¾¨ç‡æ¨¡å‹çš„èåˆæƒé‡
æ”¯æŒï¼š
- htdemucs_n: å•ç»„å…¨å±€æƒé‡
- htdemucs_nn: ä¸¤ç»„æƒé‡ï¼ˆé¢‘åŸŸ+æ—¶åŸŸï¼‰
- htdemucs_ng: å…¨å±€æƒé‡
"""

import torch
import torch.nn.functional as F
from pathlib import Path
import sys

def analyze_weight_group(raw_weights, name="èåˆæƒé‡", nfft_list=None):
    """åˆ†æä¸€ç»„æƒé‡"""
    normalized_weights = F.softmax(raw_weights, dim=0)
    num_resolutions = len(raw_weights)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {name}")
    print(f"{'='*60}")
    print(f"åˆ†è¾¨ç‡æ•°é‡: {num_resolutions}")
    print(f"åŸå§‹æƒé‡: {raw_weights}")
    print(f"å½’ä¸€åŒ–æƒé‡: {normalized_weights}")
    
    # ç”Ÿæˆåˆ†è¾¨ç‡æ ‡ç­¾
    if nfft_list is not None and len(nfft_list) == num_resolutions:
        resolutions = [f'{nfft}' for nfft in nfft_list]
    else:
        resolutions = [f'Res_{i+1}' for i in range(num_resolutions)]
    
    print(f"\nğŸ¯ æƒé‡åˆ†å¸ƒ:")
    for i, (res, weight) in enumerate(zip(resolutions, normalized_weights)):
        bar = 'â–ˆ' * int(weight * 50)
        print(f"  {res:8s}: {weight:.4f} ({weight*100:.1f}%) {bar}")
    
    # æ‰¾å‡ºæœ€åå¥½çš„åˆ†è¾¨ç‡
    max_idx = normalized_weights.argmax()
    print(f"\nğŸ† æœ€åå¥½: {resolutions[max_idx]} ({normalized_weights[max_idx]*100:.1f}%)")
    
    # æ£€æŸ¥æƒé‡æ˜¯å¦å‡åŒ€åˆ†å¸ƒ
    uniform_weight = 1.0 / num_resolutions
    is_uniform = torch.allclose(normalized_weights, torch.ones(num_resolutions) * uniform_weight, atol=1e-3)
    if is_uniform:
        print("âš ï¸  æƒé‡æ¥è¿‘å‡åŒ€åˆ†å¸ƒï¼Œå¯èƒ½è¿˜æœªå……åˆ†è®­ç»ƒ")
    else:
        print("âœ… æƒé‡å·²åˆ†åŒ–ï¼Œæ¨¡å‹æ­£åœ¨å­¦ä¹ åˆ†è¾¨ç‡åå¥½")
    
    # è®¡ç®—æƒé‡ç†µ
    entropy = -(normalized_weights * torch.log(normalized_weights + 1e-8)).sum()
    max_entropy = torch.log(torch.tensor(float(num_resolutions)))
    entropy_ratio = entropy / max_entropy
    print(f"\nğŸ“ˆ æƒé‡ç†µ: {entropy:.4f} / {max_entropy:.4f} ({entropy_ratio*100:.1f}%)")
    if entropy_ratio > 0.95:
        print("   â†’ åˆ†å¸ƒå¾ˆå‡åŒ€")
    elif entropy_ratio > 0.8:
        print("   â†’ åˆ†å¸ƒè¾ƒå‡åŒ€ï¼Œæœ‰è½»å¾®åå¥½")
    else:
        print("   â†’ åˆ†å¸ƒä¸å‡åŒ€ï¼Œæœ‰æ˜æ˜¾åå¥½")
    
    return normalized_weights

def check_fusion_weights(model_path):
    """æ£€æŸ¥æ¨¡å‹çš„èåˆæƒé‡"""
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹: {model_path}")
    
    try:
        # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        
        if 'state' not in checkpoint:
            print("âŒ æ¨¡å‹æ ¼å¼é”™è¯¯ï¼Œæœªæ‰¾åˆ°'state'å­—å…¸")
            return
        
        state_dict = checkpoint['state']
        
        # å°è¯•è·å–NFFTåˆ—è¡¨
        nfft_list = None
        if 'args' in checkpoint:
            args = checkpoint['args']
            if hasattr(args, 'htdemucs_n') and hasattr(args.htdemucs_n, 'multi_freqs'):
                multi_freqs = args.htdemucs_n.multi_freqs
                if multi_freqs:
                    nfft_list = multi_freqs
            elif hasattr(args, 'htdemucs_nn') and hasattr(args.htdemucs_nn, 'multi_freqs'):
                multi_freqs = args.htdemucs_nn.multi_freqs
                if multi_freqs:
                    nfft_list = multi_freqs
        
        # æ£€æŸ¥ä¸åŒç±»å‹çš„èåˆæƒé‡
        found_weights = False
        
        # 1. æ£€æŸ¥å•ç»„å…¨å±€æƒé‡ (htdemucs_n)
        # æ³¨æ„ï¼šå¦‚æœåŒæ—¶æœ‰final_fusion_weightsï¼Œè¯´æ˜æ˜¯nnæ¨¡å‹ï¼Œä¼šåœ¨åé¢å¤„ç†
        if 'fusion_weights' in state_dict and 'final_fusion_weights' not in state_dict:
            found_weights = True
            print("\nâœ… å‘ç°å…¨å±€èåˆæƒé‡ (htdemucs_n)")
            raw_weights = state_dict['fusion_weights']
            analyze_weight_group(raw_weights, "å…¨å±€èåˆæƒé‡", nfft_list)
            
            # æ£€æŸ¥EMAæƒé‡
            if 'weight_ema' in state_dict:
                ema_weights = state_dict['weight_ema']
                normalized_weights = F.softmax(raw_weights, dim=0)
                diff = (normalized_weights - ema_weights).abs().max()
                print(f"\nğŸ“ˆ EMAæƒé‡: {ema_weights}")
                print(f"åŸå§‹æƒé‡ä¸EMAå·®å¼‚: {diff:.6f}")
        
        # 2. æ£€æŸ¥nnæ¨¡å‹çš„åŒç»„æƒé‡
        if 'final_fusion_weights' in state_dict:
            found_weights = True
            print("\nâœ… å‘ç°htdemucs_nnæ¨¡å‹ï¼ˆåŒæƒé‡ç»“æ„ï¼‰")
            
            # ç“¶é¢ˆå¤„çš„èåˆæƒé‡ï¼ˆå…¨å±€ï¼‰
            if 'fusion_weights' in state_dict:
                bottleneck_weights = state_dict['fusion_weights']
                analyze_weight_group(bottleneck_weights, "æƒé‡1: ç“¶é¢ˆèåˆï¼ˆé¢‘åŸŸï¼‰", nfft_list)
            
            # æœ€ç»ˆè¾“å‡ºçš„æºç‰¹å¼‚æ€§èåˆæƒé‡
            final_weights = state_dict['final_fusion_weights']
            final_norm = F.softmax(final_weights, dim=-1)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š æƒé‡2: æºç‰¹å¼‚æ€§èåˆï¼ˆæ—¶åŸŸï¼‰")
            print(f"{'='*60}")
            print(f"å½¢çŠ¶: {final_weights.shape[0]}ä¸ªæº Ã— {final_weights.shape[1]}ä¸ªåˆ†è¾¨ç‡")
            
            # ç”Ÿæˆåˆ†è¾¨ç‡æ ‡ç­¾
            if nfft_list is not None and len(nfft_list) == final_weights.shape[1]:
                resolutions = [f'{nfft}' for nfft in nfft_list]
            else:
                resolutions = [f'Res_{i+1}' for i in range(final_weights.shape[1])]
            
            # ç®€æ´æ˜¾ç¤ºæ¯ä¸ªæºçš„æƒé‡
            source_names = ['Drums', 'Bass', 'Other', 'Vocals']
            print(f"\nå„æºçš„æƒé‡åˆ†å¸ƒ:")
            for i, source in enumerate(source_names[:final_weights.shape[0]]):
                weights = final_norm[i]
                weight_str = " | ".join([f"{res}: {w:.1f}%" for res, w in zip(resolutions, weights * 100)])
                print(f"  {source:8s}: {weight_str}")
            
            # è®¡ç®—å¹³å‡æƒé‡
            final_avg = final_norm.mean(dim=0)
            avg_str = " | ".join([f"{res}: {w:.1f}%" for res, w in zip(resolutions, final_avg * 100)])
            print(f"  {'å¹³å‡':8s}: {avg_str}")
            
            # å¯¹æ¯”ä¸¤ç»„æƒé‡
            if 'fusion_weights' in state_dict:
                bottleneck_norm = F.softmax(bottleneck_weights, dim=0)
                diff = (bottleneck_norm - final_avg).abs()
                
                print(f"\nğŸ”„ ä¸¤ç»„æƒé‡å¯¹æ¯”:")
                print(f"  ç“¶é¢ˆæƒé‡: {' | '.join([f'{w:.1f}%' for w in bottleneck_norm * 100])}")
                print(f"  æœ€ç»ˆå¹³å‡: {' | '.join([f'{w:.1f}%' for w in final_avg * 100])}")
                print(f"  æœ€å¤§å·®å¼‚: {diff.max():.1f}%")
                
                if diff.max() < 0.05:
                    print("  âš ï¸  ä¸¤ç»„æƒé‡æ¥è¿‘ï¼Œæºç‰¹å¼‚æ€§ä¸æ˜æ˜¾")
                else:
                    print("  âœ… ä¸¤ç»„æƒé‡æœ‰å·®å¼‚ï¼Œä¸åŒæºæœ‰ä¸åŒåå¥½")
        
        if not found_weights:
            print("âŒ æœªæ‰¾åˆ°èåˆæƒé‡ï¼Œè¿™å¯èƒ½ä¸æ˜¯å¤šåˆ†è¾¨ç‡æ¨¡å‹")
        
        if not found_weights:
            print("\nâŒ æœªæ‰¾åˆ°èåˆæƒé‡")
            # åªåœ¨æœªæ‰¾åˆ°æƒé‡æ—¶æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            print("\nğŸ” åŒ…å«'fusion'çš„é”®:")
            fusion_keys = [key for key in sorted(state_dict.keys()) if 'fusion' in key.lower()]
            if fusion_keys:
                for key in fusion_keys:
                    print(f"  - {key}")
            else:
                print("  (æœªæ‰¾åˆ°)")
                print("\nå‰20ä¸ªstate_dicté”®:")
                for key in sorted(state_dict.keys())[:20]:
                    print(f"  - {key}")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
        if Path(model_path).exists():
            check_fusion_weights(model_path)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    # é»˜è®¤æ¨¡å‹
    default_model = "outputs/xps/248n97d170e1/best.th"
    
    if Path(default_model).exists():
        check_fusion_weights(default_model)
    else:
        print(f"âŒ é»˜è®¤æ¨¡å‹ä¸å­˜åœ¨: {default_model}")
        print("\nç”¨æ³•: python check_model_weights.py <model_path>")

if __name__ == "__main__":
    main()