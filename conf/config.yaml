# Hydra 配置组合：决定了最终配置是如何由多个文件组合而成的。
# 这是一个“默认套餐”，程序会先加载这里的设置，然后可以用命令行参数覆盖它们。
defaults:
  - _self_                                    # 首先加载当前文件（config.yaml）中的所有设置。
  - dset: musdb44                             # 然后加载 `conf/dset/musdb44.yaml` 文件，用它的内容覆盖数据集（dset）相关的默认值。
  - svd: default                              # 加载 `conf/svd/default.yaml` 的 SVD 相关配置。
  - variant: default                          # 加载 `conf/variant/default.yaml` 的变体相关配置。
  - override hydra/hydra_logging: colorlog    # 强制覆盖 Hydra 的日志记录器，使用 colorlog 美化输出。
  - override hydra/job_logging: colorlog     # 同上。

dummy:                                          # 用于调试的虚拟/空部分。

# --- 数据集 (Dataset) 配置 ---
# 所有与训练/验证数据相关的设置都在这里。
dset:
  musdb: /checkpoint/defossez/datasets/musdbhq  # 官方 MUSDB-HQ 数据集的根目录路径 (需要根据你的实际路径修改)。
  musdb_samplerate: 44100                       # MUSDB 数据集的原始采样率。
  use_musdb: true                               # 是否使用 MUSDB 数据集进行训练。对于微调，如果你只想用自己的数据，可以设为 false。
  wav:                                          # 【微调关键】自定义 WAV 训练集的根目录路径。你的分轨文件应该放在这里。
  wav2:                                         # 第二个自定义 WAV 训练集的根目录路径。
  segment: 11                                   # 【性能关键】训练时，将音频切分为多少秒的片段 (segment)。值越大，上下文越长，但显存占用越高。
  shift: 1                                      # 训练时，对每个片段做多少次随机移位（shift）的数据增强。
  train_valid: false                            # 是否从训练集中切分一部分作为验证集。
  full_cv: true                                 # 是否使用完整的交叉验证数据。
  samplerate: 44100                             # 训练过程中统一使用的采样率 (会自动重采样)。
  channels: 2                                   # 训练过程中统一使用的音频通道数 (会自动转换)。
  normalize: true                               # 是否对音频进行标准化处理。
  metadata: ./metadata                          # 存储元数据的路径。
  sources: ['drums', 'bass', 'other', 'vocals'] # 【模型关键】要分离的音轨名称列表和顺序。必须和你的数据文件夹结构对应。
  valid_samples:                                # 验证集使用的样本数量。
  backend: null                                 # 指定 torchaudio 的后端，如 'soundfile'。

# --- 测试/评估 (Evaluation) 配置 ---
# 控制在验证集上进行模型评估时的行为。
test:
  save: False       # 在验证时是否保存分离出的音频文件。设为 True 可以听到验证效果。
  best: True        # 训练结束后，是否自动加载在验证集上表现最好的那个模型权重。
  workers: 2        # 评估时使用的数据加载进程数。
  every: 20         # 每训练 20 个 epoch（轮次），进行一次完整的验证评估。
  split: true       # 评估时是否启用 "Overlap" 和 "Shifts" 来获取更高质量的分离结果（但会更慢）。
  shifts: 1         # 评估时的随机移位次数。0 表示不启用，>0 会显著增加评估时间但提升分离质量。
  overlap: 0.25     # 评估时，音频片段之间重叠的比例。可以减少拼接痕迹（stitching artifacts）。
  sdr: true         # 是否计算 SDR (Signal-to-Distortion Ratio) 信号失真比作为评价指标。
  metric: 'loss'    # 在验证集上选择最佳模型时使用的指标。可以是 'loss' (损失) 或 'nsdr' (归一化 SDR)。
  nonhq:            # 用于评估的非 HQ (普通质量) MUSDB 数据集路径。

# --- 核心训练参数 ---
epochs: 360           # 训练总轮次：整个数据集将被重复学习多少遍。对于微调，这个值可以设得小一些。
batch_size: 64        # 批大小：每次更新模型权重时，同时处理多少个音频片段。显存占用的主要因素之一。
max_batches:          # 限制每个 epoch 最多处理多少个 batch。主要用于快速调试，确保代码能跑通。
                      # 如果你的数据集非常巨大，也可以用它来缩短每个 epoch 的时间。

# --- 优化器 (Optimizer) 配置 ---
# 定义了如何根据损失来更新模型权重。
optim:
  lr: 3e-4            # 学习率 (Learning Rate)：可以说是最重要的超参数。控制每次权重更新的幅度。微调时通常需要设得更小。
  momentum: 0.9       # 动量 (Momentum)：Adam 优化器的参数之一。
  beta2: 0.999        # Adam 优化器的参数之二。
  loss: l1            # 损失函数：'l1' (绝对值误差) 在音频领域常用，'mse' (均方误差) 是另一个选项。
  optim: adam         # 优化算法：Adam 是目前的主流选择。
  weight_decay: 0     # 权重衰减：一种正则化手段，用于防止模型过拟合。
  clip_grad: 0        # 梯度裁剪阈值：防止梯度爆炸。0 表示不启用。

seed: 42              # 随机种子：固定这个值可以确保每次实验的结果都可以复现。
debug: false          # 调试模式开关。
valid_apply: true     # 是否在验证时应用模型。
flag:                 # 一个空的标志位，可用于在命令行中传递自定义标志。
save_every:           # 每隔多少个 epoch 保存一次模型，而不是只保存最好的。
weights: [1., 1., 1., 1.]  # 训练/验证损失中，每个音轨所占的权重。顺序与 `dset.sources` 对应。

# --- 数据增强 (Data Augmentation) 配置 ---
# 在训练时通过各种变换“创造”新数据，是提升模型泛化能力的关键。
augment:
  shift_same: false   # 对同一首歌的不同音轨，是否应用完全相同的随机时移。
  repitch:            # 变调/变速增强。
    proba: 0.2        # 有 20% 的概率应用此增强。
    max_tempo: 12     # 节拍变化的最大范围。
  remix:              # 音轨混合增强：将不同歌曲的音轨混合在一起，创造新的训练样本。
    proba: 1          # 100% 的概率应用此增强。
    group_size: 4     # 每次从 4 首不同的歌里随机抽取音轨来混合。
  scale:              # 音量缩放增强。
    proba: 1          # 100% 的概率应用此增强。
    min: 0.25         # 最小缩放到原音量的 0.25 倍。
    max: 1.25         # 最大放大到原音量的 1.25 倍。
  flip: true          # 随机进行左右声道翻转增强。

# --- 继续训练 / 微调 (Finetuning) 配置 ---
continue_from:          # 从一个完整的 Dora 实验记录（签名）中继续训练。
continue_pretrained:    # 【微调关键】从一个预训练模型的签名继续训练（例如 'htdemucs_ft'）。这不会加载优化器状态。
pretrained_repo:        # 预训练模型所在的仓库路径或 URL。
continue_best: true     # 加载时，是加载验证集上表现最好的模型权重 (True)，还是最后一次训练的权重 (False)。
continue_opt: false     # 是否同时加载优化器的状态。对于微调，通常设为 False。

# --- 其他杂项配置 ---
misc:
  num_workers: 10     # 数据加载时使用的 CPU 进程数。
  num_prints: 4       # 每个 epoch 打印多少次训练信息。
  show: false         # 是否显示图谱等可视化信息（需要图形界面）。
  verbose: false      # 是否打印更详细的日志。

# --- 指数移动平均 (Exponential Moving Average) 配置 ---
# EMA 是一种通过平均模型在训练过程中的权重来提升最终性能和稳定性的技巧。
# Batch 级别的 EMA 在 GPU 上计算以保证速度。
ema:
  epoch: [] # 在 epoch 级别应用的 EMA 衰减率列表。
  batch: [] # 在 batch 级别应用的 EMA 衰减率列表。

use_train_segment: true  # (待移除的旧参数)
model_segment:           # 覆盖模型的分段参数，通常是训练分段的4倍。
model: demucs            # 指定要使用的模型大类。详见 `demucs/train.py`。

# --- 经典 Demucs 模型配置 (U-Net 结构) ---
demucs:
  # Channels
  channels: 64      # 基础通道数，数字越大模型越宽，参数越多。
  growth: 2         # 每层通道数的增长率。
  # Main structure
  depth: 6          # U-Net 结构的深度，即下采样/上采样的次数。
  rewrite: true     # 是否使用重写后的高效 Demucs 实现。
  lstm_layers: 0    # 是否在 U-Net 的瓶颈部分加入 LSTM 层。
  # Convolutions
  kernel_size: 8    # 卷积核大小。
  stride: 4         # 卷积步长。
  context: 1        # 卷积的上下文大小。
  # Activations
  gelu: true        # 是否使用 GELU 激活函数。
  glu: true         # 是否使用 Gated Linear Unit。
  # Normalization
  norm_groups: 4    # Group Normalization 的组数。
  norm_starts: 4    # 从第几层开始使用归一化。
  # DConv residual branch (扩张卷积残差分支)
  dconv_depth: 2    # DConv 分支的深度。
  dconv_mode: 1     # 1: 在编码器中使用, 2: 在解码器, 3: 两者都用。
  dconv_comp: 4     # DConv 压缩率。
  dconv_attn: 4     # DConv 中的注意力头数。
  dconv_lstm: 4     # DConv 中的 LSTM 层数。
  dconv_init: 1e-4  # DConv 权重的初始化缩放系数。
  # Pre/post treatment
  resample: true    # 是否在模型的输入和输出端进行重采样。
  normalize: false  # 是否在模型内部进行标准化。
  # Weight init
  rescale: 0.1      # 权重初始化时的缩放因子。

# --- Hybrid Demucs (HDemucs) 模型配置 ---
hdemucs:
  # Channels
  channels: 48          # 基础通道数。
  channels_time:        # 时域分支的通道数。
  growth: 2             # 每层通道数的增长率。
  # STFT
  nfft: 4096            # STFT (短时傅里叶变换) 的窗口大小，决定了频谱的频率分辨率。
  wiener_iters: 0       # 维纳滤波的迭代次数，0 表示不使用，用于后处理。
  end_iters: 0          # 结束时额外的维纳滤波迭代次数。
  wiener_residual: false# 是否对残差进行维纳滤波。
  cac: true             # Complex as Channels: 一种将复数频谱作为两个实数通道处理的高效技术。
  # Main structure
  depth: 6              # U-Net 深度。
  rewrite: true         # 是否使用重写后的高效实现。
  hybrid: true          # 是否使用混合时域/频域结构。
  hybrid_old: false     # 是否使用旧版的混合结构。
  # Frequency Branch
  multi_freqs: []       # 额外的频率分辨率列表，用于多分辨率处理。
  multi_freqs_depth: 3  # 多分辨率分支的深度。
  freq_emb: 0.2         # 频率嵌入的比例。
  emb_scale: 10         # 嵌入的缩放系数。
  emb_smooth: true      # 是否平滑嵌入。
  # Convolutions
  kernel_size: 8        # 卷积核大小。
  stride: 4             # 卷积步长。
  time_stride: 2        # 时域上的步长。
  context: 1            # 卷积上下文。
  context_enc: 0        # 编码器中的上下文。
  # normalization
  norm_starts: 4        # 从第几层开始归一化。
  norm_groups: 4        # 归一化组数。
  # DConv residual branch
  dconv_mode: 1         # DConv 模式。
  dconv_depth: 2        # DConv 深度。
  dconv_comp: 4         # DConv 压缩率。
  dconv_attn: 4         # DConv 注意力头数。
  dconv_lstm: 4         # DConv LSTM 层数。
  dconv_init: 1e-3      # DConv 初始化系数。
  # Weight init
  rescale: 0.1          # 权重初始化缩放因子。

# --- Torchaudio 版本的 HDemucs (一个更标准的实现) ---
torch_hdemucs:
  # Channels
  channels: 48
  growth: 2
  # STFT
  nfft: 4096
  # Main structure
  depth: 6
  freq_emb: 0.2
  emb_scale: 10
  emb_smooth: true
  # Convolutions
  kernel_size: 8
  stride: 4
  time_stride: 2
  context: 1
  context_enc: 0
  # normalization
  norm_starts: 4
  norm_groups: 4
  # DConv residual branch
  dconv_depth: 2
  dconv_comp: 4
  dconv_attn: 4
  dconv_lstm: 4
  dconv_init: 1e-3

# --- Hybrid Transformer Demucs (HTDemucs) 模型配置 (当前最先进的模型之一) ---
htdemucs:
  # --- 卷积部分 (U-Net) ---
  channels: 48          # 基础通道数。
  channels_time:        # 时域分支通道数。
  growth: 2             # 通道增长率。
  # STFT
  nfft: 4096            # STFT 窗口大小。
  wiener_iters: 0       # 维纳滤波迭代次数。
  end_iters: 0          # 结束时额外迭代次数。
  wiener_residual: false# 对残差进行维纳滤波。
  cac: true             # Complex as Channels 技术。
  # Main structure
  depth: 4              # U-Net 深度。
  rewrite: true         # 使用重写的高效实现。
  # Frequency Branch
  multi_freqs: []       # 多频率分辨率列表。
  multi_freqs_depth: 3  # 多分辨率分支深度。
  freq_emb: 0.2         # 频率嵌入比例。
  emb_scale: 10         # 嵌入缩放系数。
  emb_smooth: true      # 平滑嵌入。
  # Convolutions
  kernel_size: 8        # 卷积核大小。
  stride: 4             # 卷积步长。
  time_stride: 2        # 时域步长。
  context: 1            # 卷积上下文。
  context_enc: 0        # 编码器上下文。
  # normalization
  norm_starts: 4        # 开始归一化的层。
  norm_groups: 4        # 归一化组数。
  # DConv residual branch
  dconv_mode: 1         # DConv 模式。
  dconv_depth: 2        # DConv 深度。
  dconv_comp: 8         # DConv 压缩率。
  dconv_init: 1e-3      # DConv 初始化系数。
  # Before the Transformer
  bottom_channels: 0    # Transformer 前置层的通道数。0 表示与上一层相同。
  # --- 跨流 Transformer (Cross-Transformer) 部分 ---
  # ------ Common to all (通用参数) ------
  t_layers: 5           # Transformer Encoder 的层数。
  t_hidden_scale: 4.0   # Transformer 中前馈网络（FFN）的隐藏层维度放大系数。
  t_heads: 8            # 多头注意力机制 (Multi-Head Attention) 的头数。
  t_dropout: 0.0        # Transformer 中的 Dropout 概率。
  t_layer_scale: True   # 是否使用 LayerScale 技术来稳定训练。
  t_gelu: True          # 是否使用 GELU 激活函数。
  # ------------- Positional Embedding (位置编码) -------------
  t_emb: sin            # 位置编码的方式, 'sin' 表示经典的 sin/cos 编码。
  t_max_positions: 10000 # 缩放位置编码的最大位置。
  t_max_period: 10000.0 # sin/cos 编码的最大周期。
  t_weight_pos_embed: 1.0 # 位置编码的权重。
  t_cape_mean_normalize: True # 是否对 CAPE (Conditional Absolute Position Embeddings) 进行均值归一化。
  t_cape_augment: True      # 是否对 CAPE 进行数据增强。
  t_cape_glob_loc_scale: [5000.0, 1.0, 1.4] # CAPE 的全局/局部缩放参数。
  t_sin_random_shift: 0     # 对 sin 位置编码进行随机移位的数量。
  # ------------- norm before a transformer encoder (Encoder 前的归一化) -------------
  t_norm_in: True       # 是否在 Transformer Encoder 输入前进行归一化。
  t_norm_in_group: False# 是否使用 Group Norm。
  # ------------- norm inside the encoder (Encoder 内部的归一化) -------------
  t_group_norm: False   # 是否使用 Group Norm。
  t_norm_first: True    # 是否使用 Pre-Norm 结构 (Norm 在 Attention/FFN 之前)，有助于稳定训练。
  t_norm_out: True      # 是否在 Transformer Encoder 输出后进行归一化。
  # ------------- optim (优化相关) -------------
  t_weight_decay: 0.0   # Transformer 参数的权重衰减。
  t_lr:                 # 为 Transformer 参数设置独立的学习率 (留空则使用全局学习率)。
  # ------------- sparsity (稀疏注意力，用于提升计算效率) -------------
  t_sparse_self_attn: False   # 是否在自注意力中使用稀疏注意力。
  t_sparse_cross_attn: False  # 是否在交叉注意力中使用稀疏注意力。
  t_mask_type: diag           # 稀疏掩码的类型。
  t_mask_random_seed: 42      # 稀疏掩码的随机种子。
  t_sparse_attn_window: 400   # 稀疏注意力的窗口大小。
  t_global_window: 100        # 全局注意力的窗口大小。
  t_sparsity: 0.95            # 注意力矩阵的稀疏度。
  t_auto_sparsity: False      # 是否自动调整稀疏度。
  # Cross Encoder First (False)
  t_cross_first: False        # 是否先进行交叉注意力再进行自注意力。
  # Weight init
  rescale: 0.1                # 权重初始化缩放因子。

# --- 奇异值分解 (Singular Value Decomposition) 正则化 ---
svd:
  penalty: 0        # SVD 惩罚项的权重。
  min_size: 0.1     # 应用 SVD 的最小张量大小。
  dim: 1            # SVD 的维度。
  niters: 2         # SVD 幂迭代的次数。
  powm: false       # 是否使用幂方法。
  proba: 1          # 应用 SVD 的概率。
  conv_only: false  # 是否只对卷积层应用 SVD。
  convtr: false     # 是否对转置卷积层应用 SVD。
  bs: 1             # SVD 的批大小。

# --- 模型量化 (Quantization) 配置 ---
quant:
  diffq:            # DiffQ (Differentiable Quantization) 惩罚项, 通常是 1e-4 或 3e-4。
  qat:              # QAT (Quantization-Aware Training) 使用的比特数。
  min_size: 0.2     # 应用量化的最小张量大小。
  group_size: 8     # 量化的组大小。

# --- Dora 实验管理工具配置 ---
dora:
  dir: outputs      # 所有实验结果（日志、模型权重、配置文件快照）的输出目录。
  exclude: ["misc.*", "slurm.*", 'test.reval', 'flag', 'dset.backend'] # 保存配置快照时，排除掉一些不需要保存的项。

# --- SLURM 集群作业调度系统配置 (个人用户可以完全忽略) ---
slurm:
  time: 4320
  constraint: volta32gb
  setup: ['module load cudnn/v8.4.1.50-cuda.11.6 NCCL/2.11.4-6-cuda.11.6 cuda/11.6']

# --- Hydra 框架自身配置 ---
hydra:
  job_logging:
    formatters:
      colorlog:
        datefmt: "%m-%d %H:%M:%S" # 定义日志中日期的格式。
